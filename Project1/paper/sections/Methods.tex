\subsection{VARIATIONAL MONTE CARLO}
While trying to access the properties of a system, one often has to deal with coupled differential equations or with multidimensional integrals. In both these cases finding a solution is absolutely non trivial: an analytical expression could even not exist and using the traditional numeric methods can be very time consuming, especially for systems with a high number of degrees of freedom.

A possible alternative to face with these kind of problems is provided by the VMC method: this technique is based on a statistical approach and on the exploration of the possible configurations for a system through the generation of random numbers. At each step of a VMC simulation, a new proposal for a possible configuration is created and properly implemented algorithms relying on pseudo-random numbers discriminate between the acceptance or rejection of such move. These algorithms are built to ensure that the frequency of the states, during the walk in the configurations' space, reproduces a given probability distribution for the system of being in a given state. After a sufficiently large number of steps necessary for the system to thermalize to the desired probability distribution, the quantities of interest for the considered apparatus (e.g. energy) are provided as averages evaluated on the configurations explored during the simulation. 

The success of this technique is mainly due to its extreme versatility and to the fact that, as previously mentioned, it allows to avoid the direct treatment of integrals and differential equations. This methods reveals to be much effective in providing us with a result without needing to spend much effort in analytical or numerical evaluations. However, as it will be shown in the next sections, the results computed through this technique strongly depend on the knowledge of the function describing the probability for the system of being in a certain state. 



\subsection{LOCAL ENERGY}
One of the most relevant quantities in which we are interested for the characterization of our system is its ground state energy. The variational principle states that the expectation value of the Hamiltonian evaluated on any wavefunction that can be written as a linear combination of the system's eigenstates is an upper bound for the true ground state energy $E_0$. For our specific case, this reads 
\begin{align*}
    &E_0 \leq E [ \hat{H} ](\alpha) = \langle \Psi_T(\bm{R}, \alpha) \vert \hat{H} \vert \Psi_T(\bm{R}, \alpha) \rangle \\
    &= \frac{\int d\bm{R} \Psi_T^*(\bm{R}, \alpha) \hat{H} \Psi_T(\bm{R}, \alpha) }{\int d\bm{R} \Psi_T^*(\bm{R}, \alpha) \Psi_T(\bm{R}, \alpha)}
\end{align*}

Our aim is then to find the value of $\alpha$ that minimizes the integral reported above. A Variational Monte Carlo simulation allows to face the problem of its evaluation. First one can define a probability density function $P(\bm{R}, \bm{\alpha})$ as
\begin{equation*}
    P(\bm{R}, \bm{\alpha}) = \frac{\vert \Psi_T (\bm{R}, \bm{\alpha}) \vert^2}{\int d\bm{R} \Psi_T^*(\bm{R}, \bm{\alpha}) \Psi_T(\bm{R}, \bm{\alpha}) }
\end{equation*}
which simply describes the probability to find the system in a given state in which particles' positions are described by the collective variable $\bm{R}$. Defining then the local energy $E_L (\bm{R}, \bm{\alpha})$ as 
\begin{equation}
    E_L(\bm{R}, \bm{\alpha}) = \frac{1}{\Psi_T(\bm{R}, \bm{\alpha})} \hat{H} \Psi_T(\bm{R}, \bm{\alpha})
    \label{local_energy}
\end{equation}
one can finally rewrite the expected energy value as
\begin{equation}
    E[\hat{H}](\alpha) = \int d\bm{R} \ P(\bm{R}, \bm{\alpha}) E_L(\bm{R}, \bm{\alpha})
    \label{energy_integral}
\end{equation}
At this point one can introduce a Monte Carlo estimator
\begin{equation}
    E[\hat{H}](\alpha) \simeq \frac{1}{N_s} \sum_{i=1}^{N_s} E_L(\bm{R}_i, \bm{\alpha})
    \label{montecarlo_estimator}
\end{equation}
where $N_s$ is the number of steps performed within a Monte Carlo simulation and $\bm{R}_1, \dots, \bm{R}_{N_s}$ are sets of positions sampled from the distribution $P(\bm{R}, \alpha)$. From a statistical point of view the law of large numbers guarantees that evaluating integral in Eq.\,\ref{energy_integral} is equivalent to evaluate the sum in Eq.\,\ref{montecarlo_estimator} if $N_s \to \infty$, but since this is obviously an unattainable condition one searches for a compromise between precision and computational cost. However, even with a finite $N_s$ steps, better results in terms of both these aspects can be obtained with a previous knowledge of the analytical form of the local energy function. \\
For the system considered in this project it was possible to obtain an analytical expression for the energy of the system as a function $\alpha$ in the simple case of $N$ non-interacting particles in a $D$-dimensional spherical potential. This result will be adopted for comparisons with the estimates produced by the VMC code.
\begin{equation}
    \langle E_L \rangle (\alpha) = ND \left(\frac{\alpha}{2} + \frac{1}{8\alpha} \right)
    \label{energy_analitical}
\end{equation}



\subsubsection{ANALYTICAL FORM} \label{sec: 3.2.1 Analytical form}
For the explicit calculations that lead to the results reported below, see Appendix \ref{appendix:local_energy}. 

In the most complex case treated in the project, namely a $3D$ system of interacting particles and elliptical potential, the result is
\begin{align}
\begin{split}
    &E_L(\bm{R}, \alpha) = \alpha (2 + \beta) N + \sum_i^N \bigg[ (x_i^2 + y_i^2)\left(\frac{1}{2} - 2\alpha^2 \right) + \\
    & + z_i^2\left( \frac{1}{2} \omega_z^2 - 2\alpha^2\beta^2 \right) \bigg] -  \frac{1}{2} \sum_i^N \sum_{j\neq i} \frac{a}{r_{ij}^2 (r_{ij} - a)} \times \\
    &\times \bigg\{ -4 \alpha \left( x_i, y_i, \beta z_i \right) \cdot \mathbf{r}_{ij} + 2 + \frac{a - 2r_{ij}}{ r_{ij} - a } + \\
    &+ \mathbf{r}_{ij} \cdot \sum_{m \neq i}   \frac{\mathbf{r}_{im}}{r_{im}} \frac{a}{r_{im} \left( r_{km} - a \right)} \bigg\} \bigg\}
\end{split}
\label{local_energy_analitic_interacting}
\end{align}
The analytic expression for the local energy in the case of a $D$-dimensional system of $N$ non-interacting particles subject to a spherical potential ($a=0$, $\beta= \omega_z=1$) results to be
\begin{equation}
    E_L(\bm{R}, \alpha) = D N \alpha + \left( \frac{1}{2} - 2\alpha^2 \right) \sum_{j=1}^{N}  r_j^2
    \label{local_energy_analytic_noninteracting}
\end{equation}




\subsubsection{NUMERICAL EVALUATION OF THE SECOND DERIVATIVE}
The local energy for the considered system can be estimated recurring to the numerical evaluation of the laplacian appearing in the Hamiltonian. In general, the second derivative of a function $f(x)$ in $x=x_0$ can be numerically approximated as
\begin{equation*}
    \frac{\partial^2 f (x_0)}{\partial x^2} \approx \frac{f(x_0 + h) + f(x_0-h) - 2 f(x_0)}{h^2}
\end{equation*}
with an asymptotic error of $O(h^4)$. This method allows to avoid all the calculations cited above in order to find the analytical expression for the local energy, but provides less accurate results and implies a much greater computational effort. In fact, one can observe that, according to Eq.\,\ref{hamiltonian} and Eq.\,\ref{local_energy}, in order to estimate all the terms descending from the Laplacian appearing in the Hamiltonian of a $D$-dimensional system constituted by $N$ particles, one would need to evaluate the trial wavefunction $3ND$ times, and this procedure would have to be repeated for each step of the VMC simulation. The analytical approach described above is thus preferable, however this numerical alternative will be implemented for a comparison.




\subsection{METROPOLIS ALGORITHM}
A very simple and effective algorithm usually implemented in the framework of a VMC simulation to discriminate between the acceptance and the rejection of a proposed move is the Metropolis one. This is intimately linked with the concept of Markov chains \cite{markov}, which constitute the theoretical basis for all the possible implementation of a Monte Carlo simulation. In this framework, $P_i^{(n)}$ represents the probability of finding the system in a state $i$ at time step $n$ (assuming to have discrete time) and the transition probability matrix $W(j \rightarrow i) = W_{ij}$ gives the probability of a transition from state $j$ to state $i$. The elements $W_{ij}$ are modelled as products between an acceptance probability and a transition probability
\begin{equation*}
    W(j\rightarrow i) = A(j\rightarrow i) T(j\rightarrow i)
\end{equation*}
and this is completely legitimate, as in general the form of $W$ is unknown. For both the matrices $A$ and $T$ the following normalization condition applies
\begin{equation*}
    \sum_j A(j\rightarrow i) = \sum_j T(j\rightarrow i) = 1
\end{equation*}
The evolution of the Markov chain is then described by
\begin{align}
\begin{split}
    P_i^{(n+1)} &= \sum_j \bigg\{ A(j\rightarrow i) T(j\rightarrow i) P_j^{(n)} + \\
    &\quad + \left[1 - A(i\rightarrow j) \right] T(i\rightarrow j) P_i^{(n)} \bigg\} \\
\end{split}
\label{markovchain}
\end{align}
which expresses the fact that at each step of the simulation the state $i$ can be reached after a transition from a state $j$ or after the rejection of a proposed move, being the system already in state $i$. Ideally, for a converging Markov chain the steady state distribution $P$ is reached after an infinite number of steps, then
\begin{equation*}
    P=WP \qquad, \qquad P = \lim_{n\rightarrow \infty} P^{(n)}
\end{equation*}
Inserting this condition into Eq.\,\ref{markovchain}, we obtain the detailed balance condition
\begin{equation}
    \frac{A(j\rightarrow i)}{A(i\rightarrow j)} =  \frac{ T(i\rightarrow j) P_i}{T(j\rightarrow i) P_j}
    \label{metropolis_ratio}
\end{equation}
This is the driving equation for the Metropolis algorithm that we are going to use for the VMC code implemented in this project. The algorithm is built in such a way that, starting from the system being in a state $j$, it will propose a transition to a state $i$ with a given probability $T(j\rightarrow i)$, but then the move itself will be actually finalized with a probability $A(j\rightarrow i)$, otherwise the system will remain in its current state $i$. This last function is modelled by the Metropolis algorithm as
\begin{equation}
    A(j\rightarrow i ) = \text{min} \bigg\{ 1, \frac{T(i \rightarrow j) P_i}{T(j\rightarrow i) P_j} \bigg\}
    \label{acceptance_ratio}
\end{equation}
With this we impose that the system will surely move to a new proposed state if the ratio on the right side of of Eq.\,\ref{metropolis_ratio} is greater than 1, otherwise the move will be accepted only if a generated random number is smaller than the ratio itself. \textcolor{red}{This choice for the acceptance probability ensures that every possible state of the system can in principle be explored within a sufficiently long amount of steps and thus the ergodic hypothesis for the Markov process is preserved}. Moreover, since we are considering the ratio $P_i/P_j$, any problem due to the evaluation of multidimensional integrals related to the normalization of such PDF totally disappears. 

Possible models for the transition probability matrix $T(j\rightarrow i)$ and for the generation of the new configurations for the system are discussed below.

\subsubsection{BRUTE-FORCE METROPOLIS ALGORITHM}
A suitable choice for the transition probability matrix consists in imposing a symmetry condition, namely $T( i\rightarrow j) = T(j \rightarrow i)$. For each step of the VMC simulation the algorithm acts as follows
\begin{itemize}
    \item considering a randomly selected particle, each  component $k = \{x,\,y,\,z\}$ of its position vector is modified according to
    \begin{equation*}
        (\bm{r}')_k = (\bm{r})_k + r_{step} \ast \eta
    \end{equation*}
    where $\eta \in (-1, 1)$ is a random number generated from a uniform distribution and $r_{step}$ is a step length chosen by the user;
    \item this move gets actually accepted if $\eta' < A(j\rightarrow i)$, with $\eta' \in (0,1)$ being another random number generated from a uniform distribution and
    \begin{equation}
        A(j \rightarrow i) = \text{min} \bigg\{ 1, \frac{\vert \Psi_T(\bm{R}_i, \alpha) \vert^2 }{\vert \Psi_T(\bm{R}_j, \alpha) \vert^2 } \bigg\}
        \label{acceptance_metropolis}
    \end{equation}
\end{itemize}
We notice that in order to let the algorithm work correctly it is necessary to choose a proper step $r_{step}$: a too small value implies that a higher number of Monte Carlo step is needed to reach the convergence of the Markov chain and to explore all the configurations of the system. On the contrary, a too large step would produce a very low fraction of accepted moves during the computation, especially if the wavefunction is particularly peaked in a specific region of the space. Generally the step length used for the so-called brute-force Metropolis algorithm \cite{metropolis} is set by a comparison with the typical length which characterises the system. In our specific case, the step was chosen to be equal to the typical trap size for $^{87}$Rb atoms, namely $a_{ho}=(\hbar/m\omega_{ho})^{1/2}$, which according to the chosen units becomes $r_{step}=a_{ho}=1$. As a rule of thumb we could state that a properly chosen step length should provide an acceptance ratio around 0.5.




\subsubsection{IMPORTANCE SAMPLING}
In the brute-force Metropolis algorithm the generation of the new possible state for the system is entirely based on a uniformly distributed random variable and the information provided by the wavefunction comes to play only at the moment of the evaluation of the acceptance probability. On the contrary, one could think of exploiting the knowledge of the PDF already at the moment of the generation of the proposed transition, including a drift force so that the system is more likely to go towards high-probability configurations. This would lead to an increased acceptance ratio, meaning a more efficient simulation since less steps are wasted with the rejection of the proposed move. This is the core of the Importance sampling method \cite{hastings} in the context of Metropolis algorithm.

The idea just illustrated can be implemented starting from the Fokker-Plank equation \cite{lectures2015}, which describes the behaviour of a time-dependent PDF $P(\bm{r}, t)$ associated to a diffusive process characterized by a diffusion coefficient $D$. The equation reads
\begin{equation*}
    \frac{\partial P(\bm{r}, t)}{\partial t} = D \sum_i \frac{\partial}{\partial \bm{r}_i} \left( \frac{\partial}{\partial \bm{r}_i} - \bm{F}_i \right) P(\bm{r}, t)
\end{equation*}
where $i$ is an index running on the components of vector $\bm{r}$. The function $\bm{F}$ represent the aforementioned drift force term that we want to introduce in order to guide the system towards high-probability regions of the configurations space. The form of this drift force can be deduced by requiring that after the thermalization of the system (namely after a sufficiently long simulation time) the PDF will converge to a time-independent steady-state solution $P(\bm{r})$. Imposing this condition into the last equation, one reaches that $\bm{F}$ assumes the following form
\begin{equation*}
    \bm{F}(\bm{r}) = \frac{1}{P(\bm{r})} \nabla P(\bm{r})
\end{equation*}
The fundamental role played by this drift force in the problem becomes clearer when we consider the Langevin equation, which describes the diffusive motion of a particle under the action of a drift force $\bm{F}(x(t))$ and a random contribution $\bm{\eta}$ 
\begin{equation*}
    \frac{\partial \bm{r}(t)}{\partial t} = D \bm{F}(\bm{r}(t)) + \bm{\eta}  
\end{equation*}
By solving this differential equation assuming a discrete time step $\delta t$, we get a new algorithm for the generation of the proposed move for each component $k$ of the position vector of a randomly chosen particle, namely
\begin{equation}
    (\bm{r}')_k = (\bm{r})_k + D\delta t  (\bm{F}(\bm{r}))_k+ \xi \sqrt{\delta t}
    \label{new_position_importance}
\end{equation}
Here $\xi$ is a gaussian random variable with null mean value and unitary standard deviation. We can clearly appreciate the effect of the drift force: in fact it will introduce a tendency for the particles to generate high-probability configurations by pushing them towards regions where the PDF is flat and high-valued. A single move is then more likely to be accepted. We notice that even with this new way of generating the propose for the new position of the particles the ergodic hypothesis on the Markov chain is still preserved, since every state can possibly be reached within a sufficiently high number of steps. 

Finally, by solving the Fokker-Plank equation it is possible to derive an expression form for the transition probability appearing in Eq.\,\ref{acceptance_ratio}, which results to be in the form of the Green's function \cite{lectures2015}, namely
\begin{equation*}
    G(\bm{r}', \bm{r}, t) = \frac{1}{\left (4 \pi D \delta t\right)^{3N/2}} \exp \left[ - \frac{ \left( \bm{r}' - \bm{r} - D\delta t \bm{F}(t)\right)^2}{4D\delta t}  \right]
\end{equation*}

The importance sampling algorithm will then act as follows:
\begin{itemize}
    \item considering a randomly selected particle, each  component $k = \{x,\,y,\,z\}$ of its position vector is modified according to
    \begin{equation*}
        (\bm{r}')_k = (\bm{r})_k + D \delta t \bm{F}_k + \xi \sqrt{\delta t}
    \end{equation*}
    where $\xi$ is a gaussian random variable with $\mu = 0$ and $\sigma=1$, while $\delta t$ is the time step chosen by the user;
    \item this move gets actually accepted if $\eta < A(j\rightarrow i)$, with $\eta \in (0,1)$ is a random number generated from a uniform distribution and
    \begin{equation}
        A(j \rightarrow i) = \text{min} \bigg\{ 1, \frac{\vert \Psi_T(\bm{R}_i, \alpha)\vert^2}{\vert \Psi_T(\bm{R}_j, \alpha)\vert^2} \frac{G(\bm{r}', \bm{r}, \delta t)}{G(\bm{r}, \bm{r}', \delta t)} \bigg\}
        \label{acceptance_importance}
    \end{equation}
\end{itemize}

The expressions for the drift force obtained in the interacting and non-interacting case are reported together with the corresponding calculations in Appendix \ref{appendix:drift_force_general}.


\subsection{GRADIENT DESCENT METHOD FOR ENERGY MINIMIZATION}
Since we are dealing with a one-variational parameter problem, the search for the minimum energy of the system is reduced to find the value $\alpha_{GS}$ which satisfies
\begin{equation}
    \frac{d \langle E_L(\bm{R},\alpha) \rangle}{d \alpha} \bigg\vert_{\alpha_{GS}} = 0
    \label{null_derivative}
\end{equation}
If the function to be minimized is convex, the condition expressed here guarantees that $\alpha_{GS}$ actually corresponds to a global minimum of that function. 

For a shorter notation, in this section the dependence of $E_L$ and $\Psi_T$ on $\bm{R}$ will be omitted. The search for $\alpha_{GS}$ is performed through the standard gradient descent method \cite{painless}: after choosing an initial guess for $\alpha$, at each iteration a new value for this parameter is generated according to
\begin{equation}
    \alpha_{k+1} = \alpha_{k} - \gamma \frac{d \langle E_L(\alpha) \rangle}{d\alpha} \bigg\vert_{\alpha_k}
    \label{alpha_k}
\end{equation}
The choice of the new proposed value is thus driven by the derivative of the function that has to be minimized and by a parameter $\gamma$ chosen by the user. A too large step size may lead to a failure of the research, while a too small one to high CPU time for reaching $\alpha_{GS}$. Thus one searches again for a compromise. The method is arrested when the evaluation of the derivative of the considered function returns a value smaller than a chosen tolerance $\varepsilon$, resembling thus the content of Eq.\,\ref{null_derivative}. 

In this minimization problem we must therefore provide the algorithm with the derivative appearing in Eq.\,\ref{alpha_k}. Starting from the content of Eq.\,\ref{local_energy} and Eq.\,\ref{energy_integral}, exploiting the Hermiticity of $\hat{H}$ one gets (see Appendix \ref{appendix:local_energy_derivative})
\begin{equation}
    \frac{d\langle E_L(\alpha) \rangle}{d\alpha} = 2 \bigg[ \bigg\langle E_L(\alpha) \frac{\overline{\Psi}_T(\alpha)}{\Psi_T(\alpha)} \bigg\rangle - \langle E_L(\alpha) \rangle \bigg\langle \frac{\overline{\Psi}_T(\alpha)}{\Psi_T(\alpha)}\bigg\rangle \bigg]
    \label{dEnergy_dalpha}
\end{equation}
with 
\begin{equation*}
    \overline{\Psi}_T(\alpha) = \frac{\partial  \Psi_T(\alpha)}{\partial \alpha}
\end{equation*}
For each $\alpha_k$ the averages appearing in the last equation are evaluated through a Monte Carlo simulation performed with a relatively small amount of steps. The main aim is to find the best approximation to $\alpha_{GS}$ and once that the convergence has been reached or $k$ has exceeded an upper limit set by the user, then a larger simulation is performed and the result will be considered as the most accurate estimate of the ground state energy for the system. 

When applying the standard gradient descent method, a fundamental role is played by the initial guess for the parameter that initializes the chain of Eq.\,\ref{alpha_k}. As a matter of fact, a bad choice could lead to a wrong convergence of the method and the parameters provided by the algorithm could correspond to local minima or saddle points instead of global minima of the considered function. Nevertheless, these possible issues may apply to complicated systems in which a high number of parameters is involved. On the contrary, in the simple framework of non-interacting particles in a spherical potential treated in this project it is easy to prove the convexity of $\langle E_L(\alpha) \rangle$, which is actually minimized by $\alpha=0.5$ (see Eq.\,\ref{energy_analitical}). This result will be exploited for a comparison with the numerical ones provided by the algorithm. Regarding the interacting case, a possible analytical proof of the convexity of $\langle E_L(\alpha) \rangle$ would have been quite demanding, but the shape of the curve plotted as a function of $\alpha$ (see Section \ref{sec:results}) did not showed any unpredictable behaviour, making us still confident in the application of the gradient descent method. 


\subsection{ONE-BODY DENSITY EVALUATION}
\label{sec:one_body_density}
The main aim in evaluating the one-body density consists in observing the spatial distribution of a particle with respect to the origin of the reference system. In this project, we opted for the evaluation of $\rho$ as a function of the distance from the origin: at every Monte Carlo step we evaluate the modulus of the position vector for each particle, increasing then the count in the $k$-th bin when the obtained distance falls between $r_k$ and $r_{k+1}$. The extrema of each bin are selected by evenly spacing the interval $(0, r_{max})$ in $N_{bins}$ cells, where both $r_{max}$ and $N_{bins}$ are selected by the user. The so-built one-body density has been evaluated in the interacting case both imposing $a=0$ and $a\neq0$ in order to compare the modifications introduced by the hard-sphere potential. Using the same method, also the average displacement of the particles along some specific directions (e.g. $x$ and $z$) have been evaluated, in this case to show the effect brought by the interaction between the particles and by the switch between sperical and elliptical potential.


\subsection{BLOCKING METHOD FOR VARIANCE ANALYSIS} \label{sec:blocking_method}
As stated in Section \ref{sec:error analysis}, the correlation between data generated in a VMC simulation must be taken into account while estimating the error on an average quantity provided by the code. However, in our specific case the correlation term appearing into Eq.\,\ref{err_covariance} requires much computational power to be evaluated and a better solution consists in estimating it, avoiding a precise calculation of its value. For this reason, one efficient strategy is provided by the blocking method, which is a iterative procedure performed by repeating blocking transformation on the given data set. At each iteration we form a new bunch of data by taking the mean of every pair of subsequent elements of the array obtained at the previous step. As the number of iterations increases, the evaluation of the variance on the obtained bunch of data will include more and more of the correlation contribution of Eq.\,\ref{err_covariance}, providing thus a better estimate of the error on the desired quantity.

In a more detailed way, the method proceed as follows: first, consider a large data sample $X$ with cardinality $n=2^d$ with $d$ integer greater than 1. Since we have to provide a correct estimation for the error on the average energy coming from a VMC simulation, the elements of the sample $X$ in our case are the value of the local energy at every Monte Carlo step. We take a set $X_k$ of measurements, starting with $k=0$ (no blocking transformation has been applied to original data set), then we create a new set of data $X_{k+1}$ where the elements $x'_i$ of this new set  are the mean of subsequent pair of elements from $X_k$. At each blocking transformation the sample size is halved.
\begin{align*}
    \{X_k\} &= \{x_1, x_2, x_3 \dots x_n\} \\
    \{X_{k+1}\} &= \bigg\{x'_1=\frac{(x_1+x_2)}{2}, \dots , x'_{\frac{n}{2}}=\frac{(x_{n-1} + x_{n})}{2} \bigg\} \\
\end{align*}
Then at each transformation we compute $\sigma_k^2$ and $\gamma_k(h) = \text{cov}(\{X_k\}_i , \{X_k\}_j)=\text{cov}(\{X_k\}_i , \{X_k\}_{i+h})$ with $h =|i-j|$. These blocking transformations proceed until we end up with a sample of size of 2. The aforementioned quantities $\sigma_k^2$ and $\gamma_k(h)$ enter in the following equation
\begin{equation}
    \sigma_{\mu}^2 = \frac{\sigma_k^2}{n_k} + \frac{2}{n_k}\sum_{h=1}^{n_k - 1} \left(1-\frac{h}{n_k}\right)\gamma_k(h) = \frac{\sigma_k^2}{n_k} +e_k
    \label{eq:blocking_method}
\end{equation}
which is simply a rewriting of Eq.\,\ref{err_covariance}. Here it is expressed the fact that the variance on an average value does not simply correspond to the sample variance divided by the amount of points in the set, but it is also affected by an error $e_k$ accounting for the correlation. For each $k$ we will thus obtain a new estimate for $\sigma_{\mu}$, which will be closer and closer to the true value as $k$ increases. In fact, it has been proved \cite{Marius} that $e_k$ it can be made negligible by performing a sufficiently high number of blocking transformations. Furthermore, a method to achieve the minimum $k$ that makes $e_k$ negligible before $\sigma_k$ starts having an erratic behaviour is still provided in \cite{Marius}. 

