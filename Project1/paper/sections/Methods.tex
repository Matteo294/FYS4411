\subsection{VARIATIONAL MONTE CARLO}
While trying to access the properties of a system, one often has to deal with coupled differential equations or with multidimensional integrals. In both these cases finding a solution is absolutely non trivial: an analytical expression could even not exist and using the traditional numeric methods can be very time consuming, especially for systems with a high number of degrees of freedom.

A possible alternative to face with these kind of problems is provided by the Variational Monte Carlo (VMC) method: this technique is based on a statistical approach and on the exploration of the possible configurations of a system through the generation of random numbers. At each step of a VMC simulation, a new proposal for a possible configuration of the system is created and properly implemented algorithms relying on pseudo-random numbers discriminate between the acceptance or rejection of such move. These algorithms are built to ensure that the states touched during the walk in the configurations' space reproduce the probability distribution for the system of being in a given state. After a sufficiently large number of steps (namely when this probability distribution is sufficiently well reconstructed) the quantities of interest for the considered system (e.g. energy) are provided as averages evaluated on the configurations explored during the simulation. 

The success of this technique is mainly due to its extreme versatility and to the fact that, as previously mentioned, it allows to avoid the direct treatment of integrals and differential equations. This methods reveals to be much effective in providing us with a result without needing to spend much effort in analytical or numerical evaluations. However, as it will be shown in the next sections, the results computed through this technique strongly depends on the knowledge of the function describing the probability for the system of being in a certain state. 

From now on, we will refer to the aforementioned quantities considering them as rescaled according to what follows
\begin{equation*}
    \hbar = m = \omega_{ho} = 1
\end{equation*}
Thus $a_{ho}=1$ and $\gamma = \omega_z$.

\subsection{LOCAL ENERGY}
One of the most relevant quantities in which we are interested for the characterization of our system is its ground state energy. The variational principle states that the expectation value of the hamiltonian evaluated on any wavefunction describing the system is an upper bound for the true ground state energy $E_0$. For our specific case, this reads 
\begin{align*}
    &E_0 \leq E [ \hat{H} ](\alpha) = \langle \Psi_T(\bm{R}, \alpha) \vert \hat{H} \vert \Psi_T(\bm{R}, \alpha) \rangle \\
    &= \frac{\int d\bm{R} \Psi_T^*(\bm{R}, \alpha) \hat{H} \Psi_T(\bm{R}, \alpha) }{\int d\bm{R} \Psi_T^*(\bm{R}, \alpha) \Psi_T(\bm{R}, \alpha)}
\end{align*}

Our aim is then to find the value of $\alpha$ that minimizes the integral reported above. A Variational Monte Carlo simulation allows to face the problem of its evaluation. First one can define a probability density function $P(\bm{R}, \bm{\alpha})$ as
\begin{equation*}
    P(\bm{R}, \bm{\alpha}) = \frac{\vert \Psi_T (\bm{R}, \bm{\alpha}) \vert^2}{\int d\bm{R} \Psi_T^*(\bm{R}, \bm{\alpha}) \Psi_T(\bm{R}, \bm{\alpha}) }
\end{equation*}
which simply describes the probability to find the system in a given state in which particles' positions are described by the collective variable $\bm{R}$. Defining then the local energy $E_L (\bm{R}, \bm{\alpha})$ as 
\begin{equation}
    E_L(\bm{R}, \bm{\alpha}) = \frac{1}{\Psi_T(\bm{R}, \bm{\alpha})} \hat{H} \Psi_T(\bm{R}, \bm{\alpha})
    \label{local_energy}
\end{equation}
one can finally rewrite the expected energy value as
\begin{equation}
    E[\hat{H}](\alpha) = \int d\bm{R} P(\bm{R}, \bm{\alpha}) E_L(\bm{R}, \bm{\alpha})
    \label{energy_integral}
\end{equation}
At this point one can introduce a Monte Carlo estimator
\begin{equation}
    E[\hat{H}](\alpha) \simeq \frac{1}{N_s} \sum_{i=1}^{N_s} E_L(\bm{R}_i, \bm{\alpha})
    \label{montecarlo_estimator}
\end{equation}
where $N_s$ is the number of steps performed within a Monte Carlo simulation and $\bm{R}_1, \dots, \bm{R}_{N_s}$ are sets of positions sampled from the distribution $P(\bm{R}, \alpha)$. From a statistical point of view the law of large numbers guarantees that evaluating integral in Eq.\,\ref{energy_integral} is equivalent to evaluate the sum in Eq.\,\ref{montecarlo_estimator} if $N_s \to \infty$, but since this is obviously an unattainable condition one searches for a compromise between precision and computational cost. Better results in terms of both these aspects can be obtained with a previous knowledge of the analytical form of the local energy function. \\
For the system considered in this project it was possible to obtain an analytical expression for the energy of the system as a function $\alpha$ in the simple case of $N$ non-interacting particles in a $D$-dimensional spherical potential. This result will be adopted for comparisons with the estimates produced by the VMC code.
\begin{equation}
    \langle E_L \rangle (\alpha) = ND \left(\frac{\alpha}{2} + \frac{1}{8\alpha} \right)
    \label{energy_analitical}
\end{equation}



\subsubsection{ANALYTICAL FORM} \label{sec: 3.2.1 Analytical form}
For the explicit calculations that lead to the results reported below, see \textit{Appendix} \ref{appendix:local_energy}. 

The analytic expression for the local energy in the case of a $D$-dimensional system of $N$ non-interacting particles subject to a spherical potential ($a=0$, $\beta=1$) results to be
\begin{equation*}
    E_L(\bm{R}, \alpha) = D N \alpha + \left( \frac{1}{2} - 2\alpha^2 \right) \sum_{j=1}^{N}  r_j^2
\end{equation*}

In the more complex case of interacting particles and elliptical potential, the result is
\begin{align*}
    &E_L(\bm{R}, \alpha) = \alpha (2 + \beta) N + \sum_i^N \bigg[ (x_i^2 + y_i^2)\left(\frac{1}{2} - 2\alpha^2 \right) + \\
    & + z_i^2\left( \frac{1}{2} \omega_z^2 - 2\alpha^2\beta^2 \right) \bigg] -  \frac{1}{2} \sum_i^N \sum_{j\neq i} \frac{a}{r_{ij}^2 (r_{ij} - a)} \times \\
    &\times \bigg\{ -4 \alpha \left( x_i, y_i, \beta z_i \right) \cdot \mathbf{r}_{ij} + 2 + \frac{a - 2r_{ij}}{ r_{ij} - a } + \\
    &+ \mathbf{r}_{ij} \cdot \sum_{m \neq i}   \frac{\mathbf{r}_{im}}{r_{im}} \frac{a}{r_{im} \left( r_{km} - a \right)} \bigg\} \bigg\}
\end{align*}





\subsubsection{NUMERICAL EVALUATION OF THE SECOND DERIVATIVE}
The local energy for the considered system can be estimated recurring to the numerical evaluation of the laplacian appearing in the Hamiltonian. In general, the second derivative of a function $f(x)$ in $x=x_0$ can be numerically approximated as
\begin{equation*}
    \frac{\partial^2 f (x_0)}{\partial x^2} \approx \frac{f(x_0 + h) + f(x_0-h) - 2 f(x_0)}{h^2}
\end{equation*}
where $h$ is a sufficiently small step. This method allows to avoid all the analytical calculations cited above, but provides less accurate results and a much greater computational effort. In fact, we can deduce that, according to Eq.\,\ref{hamiltonian} and Eq.\,\ref{local_energy}, to get the local energy for a $D$-dimensional system constituted by $N$ particles we need to evaluate the trial wavefunction $3ND$ times. The analytical approach described above is thus preferable, however this numerical alternative will be implemented for a comparison.




\subsection{METROPOLIS ALGORITHM}
A very simple and effective algorithm usually implemented in the framework of a VMC simulation to discriminate between the acceptance and the rejection of a proposed move is the Metropolis one. This is intimately linked with the concept of Markov chains \cite{markov}, which constitute the theoretical basis for all the possible implementation of a Monte Carlo simulation. In this framework, $P_i^{(n)}$ provides the probability of finding the system in a state $i$ at time step $n$ (assuming to have discrete time) and the transition probability matrix $W(j \rightarrow i) = W_{ij}$ gives the probability of a transition from state $i$ to state $j$. The elements $W_{ij}$ are modelled as products between an acceptance probability and a transition probability
\begin{equation*}
    W(j\rightarrow i) = A(j\rightarrow i) T(j\rightarrow i)
\end{equation*}
and this is completely legitimate, as in general the form of $W$ is unknown. For both the matrices $A$ and $T$ the following condition applies
\begin{equation*}
    \sum_j A(j\rightarrow i) = \sum_j T(j\rightarrow i) = 1
\end{equation*}
The evolution of the Markov chain is then described by
\begin{align}
\begin{split}
    P_i^{(n+1)} &= \sum_j \bigg[ A(j\rightarrow i) T(j\rightarrow i) P_j^{(n)} + \\
    &\quad + (1 - A(i\rightarrow j)) T(i\rightarrow j) P_i^{(n)} \bigg] \\
\end{split}
\label{markovchain}
\end{align}
which expresses the fact that at each step of the simulation the state $i$ can be reached after a transition from the state $j$ or after the rejection of a proposed move. Ideally, for a converging Markov chain the steady state distribution $P$ is reached after an infinite number of steps, then
\begin{equation*}
    P=WP \qquad, \qquad P = \lim_{n\rightarrow \infty} P^{(n)}
\end{equation*}
Inserting this condition into Eq.\,\ref{markovchain}, we obtain the detailed balance condition
\begin{equation}
    \frac{A(j\rightarrow i)}{A(i\rightarrow j)} =  \frac{ T(i\rightarrow j) P_i}{T(j\rightarrow i) P_j}
    \label{metropolis_ratio}
\end{equation}
This is the driving equation for the Metropolis algorithm that we are going to use for the VMC code implemented in this project. The algorithm is built in such a way that, starting from a state $j$ it will propose a transition to a state $i$ with a given probability $T(j\rightarrow i)$, but then the move will indeed be accepted with a probability $A(j\rightarrow i)$. This last function is modelled by the Metropolis algorithm as
\begin{equation*}
    A(j\rightarrow i ) = \text{min} \bigg\{ 1, \frac{T(i \rightarrow j) P_i}{T(j\rightarrow i) P_j} \bigg\}
\end{equation*}
With this we impose that the system will surely move to a new proposed state if the ratio of Eq.\,\ref{metropolis_ratio} is greater than 1, otherwise the move will be accepted only if a generated random number is smaller than the ratio itself. This choice for the acceptance probability ensures that every possible state of the system can in principle be explored within a sufficiently long amount of steps and thus the ergodic hypothesis for the Markov process is preserved. Moreover, since we are considering the ratio of two PDFs $P_i$ and $P_j$, any problem due to the evaluation of multidimensional integrals totally disappears. 

Possible models for the transition probability matrix $T(j\rightarrow i)$ and for the generation of the new configurations for the system are discussed below.

\subsubsection{BRUTE-FORCE METROPOLIS ALGORITHM}
A suitable choice for the transition probability matrix consists in imposing a symmetry condition, namely $T( i\rightarrow j) = T(j \rightarrow i)$. For each step of the VMC simulation the algorithm acts as follows
\begin{itemize}
    \item considering a randomly selected particle, each  component $k = \{x,\,y,\,z\}$ of its position vector is modified according to
    \begin{equation*}
        (\bm{r}')_k = (\bm{r})_k + \Delta x \ast \eta
    \end{equation*}
    where $\eta \in (-0.5, 0.5)$ is a random number generated from a uniform distribution and $\Delta x$ is a step length chosen by the user;
    \item this move gets actually accepted if $\eta' < A(j\rightarrow i)$, with $\eta' \in (0,1)$ is another random number generated from a uniform distribution and
    \begin{equation}
        A(j \rightarrow i) = \text{min} \bigg\{ 1, \frac{\vert \Psi_T(\bm{R}_i, \alpha) \vert^2 }{\vert \Psi_T(\bm{R}_j, \alpha) \vert^2 } \bigg\}
        \label{acceptance_metropolis}
    \end{equation}
\end{itemize}
We notice that in order to let the algorithm work correctly it is necessary to choose a proper step $\Delta x$: a too short value would imply that a higher number of Monte Carlo step is needed to reach the convergence of the Markov chain and to explore all the configurations of the system. On the contrary, a too large step would produce a very low fraction of accepted moves during the computation, especially if the wavefunction is particularly peaked in a specific region of the space. Generally the step length used for the brute-force Metropolis algorithm \cite{metropolis} is set by a comparison with the typical length which characterises the system. In our specific case, the step was chosen to be equal to the typical trap size for $^{87}$Rb atoms, which is $a_{ho}=(\hbar/m\omega_{ho})^{1/2}$, which according to the chosen units becomes $r_{step}=a_{ho}=1$. As a rule of thumb we could state that a properly chosen step length should provide a $50\%$ acceptance ratio.




\subsubsection{IMPORTANCE SAMPLING}
In the brute-force Metropolis algorithm the generation of the new possible state for the system is entirely based on a uniformly distributed random variable and the information provided by the wavefunction comes to play only at the moment of the evaluation of the acceptance probability. On the contrary, one could think of exploiting the PDF already at the moment of the generation of the proposed transition so that the system is more likely to go towards high-probability configurations. This would lead to an increased acceptance ratio, meaning a more efficient simulation. This is the core of the Importance sampling method \cite{hastings} in the context of Metropolis algorithm.

The idea just illustrated can be implemented starting from the Fokker-Plank equation \cite{lectures2015}, which describes the behaviour of a time-dependent PDF $P(\bm{r}, t)$ associated to a diffusive process characterized by a diffusion coefficient $D$. The equation reads
\begin{equation*}
    \frac{\partial P(\bm{r}, t)}{\partial t} = D \sum_i \frac{\partial}{\partial \bm{r}_i} \left( \frac{\partial}{\partial \bm{r}_i} - \bm{F}_i \right) P(\bm{r}, t)
\end{equation*}
where $i$ is an index running on the components of vector $\bm{r}$. The function $\bm{F}$ represent the aforementioned drift force term that we want to introduce in order to guide the system towards high-probability regions of the configurations space. The form of this drift force can be deduced by requiring that after the thermalization of the system (namely after a sufficiently long simulation time) the PDF will converge to a time-independent steady-state solution $P(\bm{r})$. It is possible to proof (see \textit{Appendix} \ref{appendix:drift_force_general}) that this condition is reached if $\bm{F}$ assumes the following form
\begin{equation*}
    \bm{F}(\bm{r}) = \frac{1}{P(\bm{r})} \nabla P(\bm{r})
\end{equation*}
The fundamental role played by this drift force in the problem becomes clearer when we consider the Langevin equation, which describes the diffusive motion of a particle under the action of a drift force $\bm{F}(x(t))$ and a random contribution $\bm{\eta}$ 
\begin{equation*}
    \frac{\partial \bm{r}(t)}{\partial t} = D \bm{F}(\bm{r}(t)) + \bm{\eta}  
\end{equation*}
By solving this differential equation assuming a discrete time step $\delta t$, we get a new algorithm for the generation of the proposed move for a randomly chosen particle, namely
\begin{equation}
    \bm{r}' = \bm{r} + D \bm{F}(\bm{r}) \delta t + \xi \sqrt{\delta t}
    \label{new_position_importance}
\end{equation}
where $\xi$ is a gaussian random variable with null mean value and unitary standard deviation. Here we can clearly appreciate the effect of the drift force: in fact it will introduce a tendency for the particles to generate high-probability configurations by pushing them towards regions where the PDF is flat and high-valued. A single move is then more likely to be accepted. We notice that even with this new way of generating the propose for the new position of the particles, the erogdic hypothesis on the Markov chain is still preserved, since every state can possibly be reached within a sufficiently high number of steps. 

Finally, by solving the Fokker-Plank equation it is possible to derive an expression form for the transition probability appearing in Eq.\,\ref{metropolis_ratio}, which results to be in the form of the Green's function \cite{lectures2015}, namely
\begin{equation*}
    G(\bm{r}', \bm{r}, t) = \frac{1}{\left (4 \pi D \delta t\right)^{3N/2}} \exp \left[ - \frac{ \left( \bm{r}' - \bm{r} - D\delta t \bm{F}(t)\right)^2}{4D\delta t}  \right]
\end{equation*}

The importance sampling algorithm will then act as follows:
\begin{itemize}
    \item considering a randomly selected particle, each  component $k = \{x,\,y,\,z\}$ of its position vector is modified according to
    \begin{equation*}
        (\bm{r}')_k = (\bm{r})_k + D \delta t \bm{F}_k + \xi \sqrt{\delta t}
    \end{equation*}
    where $\xi$ is a gaussian random variable with $\mu = 0$ and $\sigma=1$, while $\delta t$ is the time step chosen by the user;
    \item this move gets actually accepted if $\eta < A(j\rightarrow i)$, with $\eta \in (0,1)$ is a random number generated from a uniform distribution and
    \begin{equation}
        A(j \rightarrow i) = \text{min} \bigg\{ 1, \frac{\vert \Psi_T(\bm{R}_i, \alpha)\vert^2}{\vert \Psi_T(\bm{R}_j, \alpha)\vert^2} \frac{G(\bm{r}', \bm{r}, \delta t)}{G(\bm{r}, \bm{r}', \delta t)} \bigg\}
        \label{acceptance_importance}
    \end{equation}
\end{itemize}



\subsection{GRADIENT DESCENT METHOD FOR ENERGY MINIMIZATION}
Since we are dealing with a one-variational parameter problem, the search for the minimum energy of the system is reduced to find the value $\alpha_{opt}$ which satisfies
\begin{equation}
    \frac{d \langle E_L(\bm{R},\alpha) \rangle}{d \alpha} \bigg\vert_{\alpha_{opt}} = 0
    \label{null_derivative}
\end{equation}
The condition expressed here guarantees that $\alpha_{opt}$ actually corresponds to a global minimum only if the function to be minimized is convex.

For a shorter notation, in this section the dependence of $E_L$ and $\Psi_T$ on $\bm{R}$ will be omitted. The search for $\alpha_{opt}$ is performed through the standard gradient descent method \cite{painless}: after choosing an initial guess for $\alpha$, at each iteration a new value for this parameter is generated according to
\begin{equation}
    \alpha_{k+1} = \alpha_{k} - \gamma \frac{d \langle E_L(\alpha) \rangle}{d\alpha} \bigg\vert_{\alpha_k}
    \label{alpha_k}
\end{equation}
The choice of the new proposed value is thus driven by the derivative of the function that has to be minimized and by a parameter $\gamma$ chosen by the user. A too large step size may lead to a failure of the research, while a too small one to high CPU time for reaching $\alpha_{opt}$. Thus one searches again for a compromise. The method is arrested when the distance between two consecutively generated $\alpha$ values is smaller than a chosen tolerance $\varepsilon$, resembling thus the content of Eq.\,\ref{null_derivative}. 

In this minimization problem we must therefore provide the algorithm with the derivative appearing in Eq.\,\ref{alpha_k}. Starting from the content of Eq.\,\ref{local_energy} and Eq.\,\ref{energy_integral}, exploiting the Hermiticity of $\hat{H}$ one gets (see \ref{appendix:local energy as function of alpha } )
\begin{equation}
    \frac{d\langle E_L(\alpha) \rangle}{d\alpha} = 2 \bigg[ \bigg\langle E_L(\alpha) \frac{\overline{\Psi}_T(\alpha)}{\Psi_T(\alpha)} \bigg\rangle - \langle E_L(\alpha) \rangle \bigg\langle \frac{\overline{\Psi}_T(\alpha)}{\Psi_T(\alpha)}\bigg\rangle \bigg]
    \label{dEnergy_dalpha}
\end{equation}
with 
\begin{equation*}
    \overline{\Psi}_T(\alpha) = \frac{\partial  \Psi_T(\alpha)}{\partial \alpha}
\end{equation*}
For each $\alpha_k$ the averages appearing in the last equation are evaluated through a Monte Carlo simulation performed with a relatively small amount of steps. In fact, at this point we are not interested in reaching a high precision on the estimated quantities: the main aim is to find the best approximation to $\alpha_{opt}$ and once that the convergence has been reached or $k$ has exceeded an upper limit set by the user, then a larger simulation is performed and the result will be considered as the most accurate estimate of the ground state energy for the system. 

When applying the standard gradient descent method, a fundamental role is played by the initial guess for the parameter that initializes the chain of Eq.\,\ref{alpha_k}. As a matter of fact, a bad choice could lead to a wrong convergence of the method and the parameters provided by the algorithm could correspond to local minima or saddle points instead of global minima of the considered function. Nevertheless, these possible issues may apply to complicated systems in which a high number of parameters is involved. On the contrary, for the apparatus considered in this project the function $\langle E_L(\alpha) \rangle$ will show a good behaviour that prevents from encountering any issue in the application of the aforementioned algorithm. Moreover, in the simple framework of non-interacting particles in a spherical potential it is easy to prove the convexity of $\langle E_L(\alpha) \rangle$, which is actually minimized by $\alpha=0.5$ (see Eq.\,\ref{energy_analitical}). This result will be exploited for a comparison with the numerical ones provided by the algorithm. 



\subsection{ONE-BODY DENSITY EVALUATION}
\label{sec:one_body_density}
The main aim in evaluating the one-body density consists in observing the spatial distribution of a particle with respect to the origin of the reference system. In this project, we opted for the evaluation of $\rho$ as a function of the distance from the origin: at every Monte Carlo step we evaluate the modulus of the position vector for each particle, increasing then the count for the $k$-th bin when the obtained distance falls between $r_k$ and $r_{k+1}$. The extrema of each bin are selected by evenly spacing the interval $(0, r_{max})$ in $N_{bins}$ cells, where both $r_{max}$ and $N_{bins}$ are selected by the user. The so-built one-body density has been evaluated in the interacting case both imposing $a=0$ and $a=0.0043$ in order to compare the modifications introduced by the hard-sphere potential.


\subsection{BLOCKING METHOD FOR VARIANCE ANALYSIS} \label{sec:blocking_method}
As stated in \textit{Section} \ref{sec:error analysis}, the correlation between data generated in a VMC simulation must be taken into account while estimating the error on an average quantity provided by the code. However, in our specific case the correlation term appearing into Eq.\,\ref{err_covariance} requires much computational power to be evaluated and a better solution consists in estimating it, avoiding a precise calculation of its value. For this reason, one efficient strategy is provided by the Blocking method, which is a iterative procedure performed by repeating blocking transformation on the given data set. At each iteration we form a new bunch of data by taking the mean of every pair of subsequent elements of the initial array. This reduces the correlations of data within each new set and it gives us an estimation of the variance in a less expensive computational way. 

In a more detailed way, the method proceed as follows: first, consider a large data sample $X$ with cardinality $n=2^d$ with $d$ integer greater than 1. Since we have to provide a correct estimation for the local energy error, the elements of the sample $X$ in our case are the value of the local energy at every Monte Carlo step. We take a sample $X_k$, starting with $k=0$ (no blocking transformation has been applied to original data set), then we create a new set of data $X_{k+1}$ where the elements of this new set $x'_i$ are the mean of subsequent pair of elements from $X_k$. At each blocking transformation the sample size is halved.
\begin{align*}
    \{X_k\} &= \{x_1, x_2, x_3 \dots x_n\} \\
    \{X_{k+1}\} &= \bigg\{x'_1=\frac{(x_1+x_2)}{2}, \dots , x'_{\frac{n}{2}}=\frac{(x_{n-1} + x_{n})}{2} \bigg\} \\
\end{align*}
Then at each transformation we compute $\sigma_k^2$ and $\gamma_k(h) = \text{cov}(\{X_k\}_i , \{X_k\}_j)=\text{cov}(\{X_k\}_i , \{X_k\}_{i+h})$ with $h =|i-j|$. These blocking transformations proceed until we end up with a sample of size of 2. The aforementioned quantities $\sigma_k^2$ and $\gamma_k(h)$ enter in the following equation
\begin{equation}
    \sigma_{\mu}^2 = \frac{\sigma_k^2}{n_k} + \frac{2}{n_k}\sum_{h=1}^{n_k - 1} \left(1-\frac{h}{n_k}\right)\gamma_k(h) = \frac{\sigma_k^2}{n_k} +e_k
    \label{eq:blocking_method}
\end{equation}
which is simply a rewriting of Eq.\,\ref{err_covariance}. Here it is expressed the fact that the variance on an average value does not simply correspond to the sample variance divided by the amount of points in the set, but it is also affected by an error $e_k$ accounting for the correlation. For each $k$ we will thus obtain a new estimate for $\sigma_{\mu}$, which will be closer and closer to the true value as $k$ increases. In fact, it has been proved \cite{Marius} that $e_k$ it can be made negligible by performing a sufficiently high number of blocking transformations. Furthermore, a method to achieve the minimum $k$ that makes $e_k$ negligible before $\sigma_k$ starts having an erratic behaviour is still provided in \cite{Marius}. 

