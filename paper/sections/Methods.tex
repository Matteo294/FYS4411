\subsection{VARIATIONAL MONTE CARLO}
While trying to access the properties of a system, one often has to deal with a coupled differential equations or with multidimensional integrals. In both these cases finding a solution is absolutely non trivial: an analytical expression could even not exist and using the traditional numeric methods can be very time consuming, especially for systems with a high number of degrees of freedom.

A possible alternative to face with these kind of problems is provided by the Variational Monte Carlo (VMC) method: this technique is based on a statistical approach and on the exploration of the possible configurations of a system through the generation of random numbers. At each step of a VMC simulation, a new proposal for a possible configuration of the system is created and properly implemented algorithms relying on pseudo-random numbers discriminate between the acceptance or rejection of such move. These algorithms are built to ensure that the states touched during the walk in the configurations' space reproduce the probability distribution for the system of being in a given state. After a sufficiently large number of steps (namely when this probability distribution is sufficiently well reconstructed) the quantities of interest for the considered system (e.g. energy) are provided as averages evaluated on the configurations explored during the simulation. 

The success of this technique is mainly due to its extreme versatility and to the fact that, as previously mentioned, it allows to avoid the direct treatment of integrals and differential equations. This methods reveals to be much effective in providing us with a result without needing to spend much effort in analytical or numerical evaluations. However, as it will be shown in the next sections, the results computed through this technique strongly depends on the knowledge of the function describing the probability for the system of being in a certain state. 


\subsection{LOCAL ENERGY}
One of the most relevant quantities in which we are interested for the characterization of our system is its ground state energy. The variational principle states that the expectation value of the hamiltonian evaluated on any wavefunction describing the system is an upper bound for the true ground state energy $E_0$. For our specific case, this reads 
\begin{align*}
    &E_0 \leq E [ \hat{H} ](\alpha) = \langle \Psi_T(\bm{R}, \alpha) \vert \hat{H} \vert \Psi_T(\bm{R}, \alpha) \rangle \\
    &= \frac{\int d\bm{R} \Psi_T^*(\bm{R}, \alpha) \hat{H} \Psi_T(\bm{R}, \alpha) }{\int d\bm{R} \Psi_T^*(\bm{R}, \alpha) \Psi_T(\bm{R}, \alpha)}
\end{align*}
where $\Psi_T(\bm{R},\alpha)$ is the trial wavefunction associated to the system and $\bm{R}$ is a collective variable containing all the coordinates of the particles in the problem. 

Our aim is then to find the value of $\alpha$ that minimized the integral reported above. A Variational Monte Carlo (VMC) simulation allows to face the problem of its evaluation. First one can define a probability density function $P(\bm{R}, \bm{\alpha})$ as
\begin{equation*}
    P(\bm{R}, \bm{\alpha}) = \frac{\vert \Psi_T (\bm{R}, \bm{\alpha}) \vert^2}{\int d\bm{R} \Psi_T^*(\bm{R}, \bm{\alpha}) \Psi_T(\bm{R}, \bm{\alpha}) }
\end{equation*}
which simply describes the probability to find the system in a given state in which particles' positions are described by the collective variable $\bm{R}$. Defining then the local energy $E_L (\bm{R}, \bm{\alpha})$ as 
\begin{equation}
    E_L(\bm{R}, \bm{\alpha}) = \frac{1}{\Psi_T(\bm{R}, \bm{\alpha})} \hat{H} \Psi_T(\bm{R}, \bm{\alpha})
    \label{local_energy}
\end{equation}
one can finally rewrite the expected energy value as
\begin{equation}
    E[\hat{H}](\alpha) = \int d\bm{R} P(\bm{R}, \bm{\alpha}) E_L(\bm{R}, \bm{\alpha})
    \label{energy_integral}
\end{equation}
At this point one can introduce a Monte Carlo estimator
\begin{equation}
    E[\hat{H}](\alpha) \simeq \frac{1}{N_s} \sum_{i=1}^{N_s} E_L(\bm{R}_i, \bm{\alpha})
    \label{montecarlo_estimator}
\end{equation}
where $N_s$ is the number of steps performed within a Monte Carlo simulation and $\bm{R}_1, \dots, \bm{R}_{N_s}$ are sets of positions sampled from the distribution $P(\bm{R}, \alpha)$. From a statistical point of view the law of large numbers guarantees that evaluating integral in Eq.\,\ref{energy_integral} is equivalent to evaluate the sum in Eq.\,\ref{montecarlo_estimator} if $N_s \to \infty$, but since this is obviously an unattainable condition one searches for a compromise between precision and computational cost. Better results in terms of both these aspects can be obtained with a previous knowledge of the analytical form of the local energy function. \\
For the system considered in this project it was possible to obtain an analytical expression for the energy of the system as a function $\alpha$ in the simple case of non-interacting particles in a spherical potential. This result will be adopted for comparisons with the estimates produced by the VMC code.
\begin{equation*}
    (instert-expression-here)
\end{equation*}



\subsubsection{ANALYTICAL FORM}
For the explicit calculations that lead to the results reported below, see \textit{Appendix} \ref{appendix:local_energy}. 

The analytic expression for the local energy in the case of a $D$-dimensional system of $N$ non-interacting particles subject to a spherical potential ($a=0$, $\beta=1$) results to be
\begin{equation*}
    E_L(\bm{R}, \alpha) = D N \alpha + \left( \frac{1}{2} - 2\alpha^2 \right) \sum_{j=1}^{N}  r_j^2
\end{equation*}

In the more complex case of interacting particles and elliptical potential, the result is
\begin{align*}
    &E_L(\bm{R}, \alpha) = \alpha (2 + \beta) N + \sum_i^N \bigg[ (x_i^2 + y_i^2)\left(\frac{1}{2} - 2\alpha^2 \right) + \\
    & + z_i^2\left( \frac{1}{2} \omega_z^2 - 2\alpha^2\beta^2 \right) \bigg] -  \frac{1}{2} \sum_i^N \sum_{j\neq i} \frac{a}{r_{ij}^2 (r_{ij} - a)} \times \\
    &\times \bigg\{ -4 \alpha \left( x_i, y_i, \beta z_i \right) \cdot \mathbf{r}_{ij} + 2 + \frac{a - 2r_{ij}}{ r_{ij} - a } + \\
    &+ \mathbf{r}_{ij} \cdot \sum_{m \neq i}   \frac{\mathbf{r}_{im}}{r_{im}} \frac{a}{r_{im} \left( r_{km} - a \right)} \bigg\} \bigg\}
\end{align*}





\subsubsection{NUMERICAL EVALUATION OF THE SECOND DERIVATIVE}
The local energy for the considered system can be estimated recurring to the numerical evaluation of the laplacian appearing in the Hamiltonian. In general, the second derivative of a function $f(x)$ in $x=x_0$ can be numerically approximated as
\begin{equation*}
    \frac{\partial^2 f (x_0)}{\partial x^2} \approx \frac{f(x_0 + h) + f(x_0-h) - 2 f(x_0)}{h^2}
\end{equation*}
where $h$ is a sufficiently small step. This method allows to avoid all the analytical calculations cited above, but provides less accurate results and a much greater computational effort. In fact, we can deduce that, according to Eq.\,\ref{hamiltonian} and Eq.\,\ref{local_energy}, to get the local energy for a $D$-dimensional system constituted by $N$ particles we need to evaluate the trial wavefunction $3ND$ times. The analytical approach described above is thus preferable, however this numerical alternative will be implemented for a comparison.


\subsection{METROPOLIS ALGORITHM}
As discussed in the previous section, by using a Monte Carlo approach our problem is reduced to simulate a random walk in the space of configurations for our system. Each new proposed state must be sampled from a given distribution: as a consequence, each possible configuration of the system should in principle be reachable within a sufficient number of steps. An algorithm that obeys this condition is called ergodic and this constitutes an essential requirement for a correct reconstruction of the PDF within a random walk in the configuration space. With the ergodic hypothesis we are trying to ensure that the results are not biased by the fact that the system remains always in the most probable configurations. 

A very simple and effective erogidic algorithm typically used with the Monte Carlo schematics for the generation of the new configuration at every step is the Metropolis one: it is based on the concept of Markov chain. We consider a generic PDF $P_i^{(n)}$ which provides the probability of finding the system in a state $i$ at time step $n$ (assuming to have discrete time). We can then introduce the so-called transition probability matrix $W(j \rightarrow i) = W_{ij}$ which instead gives the probability of a transition from state $i$ to state $j$ (in this context $P_i^{(n)}$ can be interpreted an element of a vector). For a Markov process it is true that
\begin{equation}
    P_i^{(n+1)} = \sum_{i} ( j \rightarrow i) P_j^{(n)} \iff \bm{P}^{(n+1)} = \bm{W} \bm{P}^{(n)}
    \label{markovchain}
\end{equation}
namely the probability of finding the system in state $i$ at time step $n+1$ depends only on the set of probabilities related to the previous instant. The following conditions must be also satisfied at every time step, due to the normalization of the probabilities
\begin{equation*}
    \sum_i P_i^{(n)} = \sum_j W_{ij} = 1
\end{equation*}
A Markov chain is said to be convergent if for sufficiently long times the temporal dependence contained in Eq.\,\ref{markovchain} disappears, in formulas
\begin{equation*}
     \bm{P}^{(n)} = \bm{W} \bm{P}^{(n)} \qquad \mbox{for } n \rightarrow \infty
\end{equation*}
It is possible to demonstrate that for a converging Markov chain the vector $\bm{P}^{(SS)} = \lim_{n\rightarrow \infty} \bm{P}^{(n)}$ representing the steady state (SS) for the chain coincides with the eigenvector of the transition probability matrix with eigenvalue $\lambda = 1$, which is also the highest eigenvalue for that matrix. The vector $\bm{P}^{(SS)}$ will then obey the following
\begin{equation}
    \bm{P}^{(SS)} = \bm{W} \bm{P}^{(SS)}
    \label{convergence_markov_chain}
\end{equation}
Assuming now the convergence of the Markov chain describing our system, we can go further in building the algorithm by modelling the elements of transition probability matrix as products between an acceptance probability and a transition probability
\begin{equation*}
    W(j\rightarrow i) = A(j\rightarrow i) T(j\rightarrow i)
\end{equation*}
This is completely legitimate, as in general the form of $\bm{W}$ is unknown. For both the matrices $A$ and $T$ the following condition applies
\begin{equation*}
    \sum_j A(j\rightarrow i) = \sum_j T(j\rightarrow i) = 1
\end{equation*}


The condition contained in Eq.\ref{convergence_markov_chain} becomes then
\begin{align*}
    P_i^{(SS)} &= \sum_j \left[ A(j\rightarrow i) T(j\rightarrow i) P_j^{(SS)} + (1 - A(i\rightarrow j)) T(i\rightarrow j) P_i^{(SS)} \right] \\
    &= \sum_j A(j\rightarrow i) T(j\rightarrow i) P_j^{(SS)} + P_i^{(SS)} \cancelto{1}{\sum_j T(i\rightarrow j)} - P_i^{(SS)} \sum_j A(i\rightarrow j) T(i\rightarrow j)  \\
    &= P_i^{(SS)} + \sum_j \left[ A(j\rightarrow i) T(j\rightarrow i) P_j^{(SS)} -  A(i\rightarrow j) T(i\rightarrow j) P_i^{(SS)}  \right]
\end{align*}
In principle imposing that the sum is null does not prevent cyclic solutions for Eq.\,\ref{convergence_markov_chain}, and thus a stronger statement is required. Setting each term of the sum to be null guarantees the validity of the equation and we obtain the detailed balance condition
\begin{equation}
    \frac{A(j\rightarrow i)}{A(i\rightarrow j)} =  \frac{ T(i\rightarrow j) P_i^{(SS)}}{T(j\rightarrow i) P_j^{(SS)}}
    \label{metropolis_ratio}
\end{equation}
This is the driving equation for the Metropolis algorithm that we are going to use for the VMC code implemented in this project. The algorithm is built in such a way that, starting from a state $j$ it will propose a transition to a state $i$ with a given probability $T(j\rightarrow i)$, but then the move will indeed be accepted with a probability $A(j\rightarrow i)$. This last function is modelled by the Metropolis algorithm as
\begin{equation*}
    A(j\rightarrow i ) = \text{min} \bigg\{ 1, \frac{T(i \rightarrow j) P_i^{(SS)}}{T(j\rightarrow i) P_j^{(SS)}} \bigg\}
\end{equation*}
With this we impose that the system will surely move to a new proposed state if the ratio of Eq.\,\ref{metropolis_ratio} is greater than 1, otherwise the move will be accepted only if a generated random number is smaller than the ratio itself. This choice for the acceptance probability ensures that every possible state of the system can in principle be explored within a sufficiently long amount of steps and thus the ergodic hypothesis is preserved. Moreover, since we are considering the ratio of two PDFs $P_i$ and $P_j$, any problem due to the evaluation of multidimensional integrals totally disappears. 

Possible models for the transition probability matrix $T(j\rightarrow i)$ and for the generation of the new configurations for the system are discussed below.



\subsection{Brute-force Metropolis algorithm}
A suitable choice for the transition probability matrix consists in imposing a symmetry condition, namely $T( i\rightarrow j) = T(j \rightarrow i)$. For each step of the VMC simulation the algorithm acts as follows
\begin{itemize}
    \item considering a randomly selected particle, each  component $k = \{x,\,y,\,z\}$ of its position vector is modified according to
    \begin{equation*}
        (\bm{r}')_k = (\bm{r})_k + \Delta x \ast \eta
    \end{equation*}
    where $\eta \in (-0.5, 0.5)$ is a random number generated from a uniform distribution and $\Delta x$ is a step length chosen by the user;
    \item this move gets actually accepted if $\eta' < A(j\rightarrow i)$, with $\eta' \in (0,1)$ is another random number generated from a uniform distribution and
    \begin{equation*}
        A(j \rightarrow i) = \text{min} \bigg\{ 1, \frac{P_i}{P_j} \bigg\}
    \end{equation*}
\end{itemize}
We notice that in order to let the algorithm work correctly it is necessary to choose a proper step $\Delta x$: a too short value would imply that a higher number of Monte Carlo step is needed to reach the convergence of the Markov chain and to explore all the configurations of the system. On the contrary, a too large step would produce a very low fraction of accepted moves during the computation, especially if the wavefunction is particularly peaked in a specific region of the space. Generally the step length used for the brute-force Metropolis algorithm is set by a comparison with the typical length which characterises the system. For our specific case, starting from the hamiltonian of Eq.\,\ref{hamiltonian} it is possible to demonstrate (see \textit{Appendix B}) that this typical length unit corresponds to 
\begin{equation*}
    \Delta x = \sqrt{\frac{m \omega}{\hbar}}
\end{equation*}
In any case, as a rule of thumb we could state that a properly chosen step length should provide a $50\%$ acceptance ratio. 






\subsection{Importance Sampling}
In the brute-force Metropolis algorithm the generation of the new possible state for the system is entirely based on a uniformly distributed random variable and the information provided by the PDF for the system comes to play only at the moment of the evaluation of the acceptance probability. On the contrary, one could think of exploiting the PDF already at the moment of the generation of the proposed transition so that the system is more likely to go towards high-probability configurations. This would lead to an increased acceptance ratio, meaning a more efficient simulation. This is the core of the Importance sampling method in the context of Metropolis algorithm.

The idea just illustrated can be implemented starting from the Fokker-Plank equation, which describes the behaviour of a time-dependent PDF $P(\bm{r}, t)$ associated to a diffusive process characterized by a diffusion coefficient $D$. The equation reads
\begin{equation*}
    \frac{\partial P(\bm{r}, t)}{\partial t} = D \sum_i \frac{\partial}{\partial \bm{r}_i} \left( \frac{\partial}{\partial \bm{r}_i} - \bm{F}_i \right) P(\bm{r}, t)
\end{equation*}
where $i$ is an index running on the components $\{x,\,y,\,z\}$. The function $\bm{F}$ represent the aforementioned drift force term that we want to introduce in order to guide the system towards high-probability regions of the configurations space. The form of this drift force can be deduced by requiring that after the thermalization of the system (namely after a sufficiently long simulation time) the PDF will converge to a time-independent steady-state solution $P(\bm{r})$. It is possible to proof that this condition is reached if $\bm{F}$ assumes the following form
\begin{equation*}
    \bm{F}(\bm{r}) = \frac{1}{P(\bm{r})} \nabla P(\bm{r})
\end{equation*}
The fundamental role played by this drift force in the problem becomes clearer when we consider the Langevin equation, which describes the diffusive motion of a particle under the action of a drift force $\bm{F}(x(t))$ and a random contribution $\bm{\eta}$ 
\begin{equation*}
    \frac{\partial \bm{r}(t)}{\partial t} = D \bm{F}(\bm{r}(t)) + \bm{\eta}  
\end{equation*}
By solving this differential equation assuming a discrete time step $\delta t$, we get a new algorithm for the generation of the proposed move for a randomly chosen particle, namely
\begin{equation*}
    \bm{r}' = \bm{r} + D \bm{F}(\bm{r}) \delta t + \xi \sqrt{\delta t}
\end{equation*}
where $\xi$ is a gaussian random variable with null mean value and unitary standard deviation. Here we can clearly appreciate the effect of the drift force: in fact it will introduce a tendency for the particles to generate high-probability configurations by pushing them towards regions where the PDF is flat and high-valued. A single move is then more likely to be accepted. We notice that even with this new way of generating the propose for the new position of the particles, the erogdicity of the algorithm is still preserved, since every state can possibly be reached within a sufficiently high number of steps. 

Finally, by solving the Fokker-Plank equation it is possible to derive an expression form for the transition probability appearing in Eq.\,\ref{metropolis_ratio}, which results to be in the form of the Green's function, namely
\begin{equation*}
    G(\bm{r}', \bm{r}, t) = \frac{1}{\left (4 \pi D \delta t\right)^{3N/2}} \exp \left[ - \frac{ \left( \bm{r}' - \bm{r} - D\delta t \bm{F}(t)\right)^2}{4D\delta t}  \right]
\end{equation*}

The importance sampling algorithm will then act as follows:
\begin{itemize}
    \item considering a randomly selected particle, each  component $k = \{x,\,y,\,z\}$ of its position vector is modified according to
    \begin{equation*}
        (\bm{r}')_k = (\bm{r})_k + D \delta t \bm{F}_k + \xi \sqrt{\delta t}
    \end{equation*}
    where $\xi$ is a gaussian random variable with $\mu = 0$ and $\sigma=1$, while $\Delta t$ is the time step chosen by the user;
    \item this move gets actually accepted if $\eta < A(j\rightarrow i)$, with $\eta \in (0,1)$ is a random number generated from a uniform distribution and
    \begin{equation*}
        A(j \rightarrow i) = \text{min} \bigg\{ 1, \frac{P(\bm{r}')}{P(\bm{r})} \frac{G(\bm{r}', \bm{r}, \delta t)}{G(\bm{r}, \bm{r}', \delta t)} \bigg\}
    \end{equation*}
\end{itemize}



